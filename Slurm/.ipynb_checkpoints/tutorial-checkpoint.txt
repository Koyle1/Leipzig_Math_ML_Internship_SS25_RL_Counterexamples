How to run code on the cluster?

1) Build the conda enviorment for the needed dependencies
-Open Terminal
-if you are not already in this repository where this file is located, change to it
-run "module load Anaconda3"
-run "conda init"
-Close your terminal & reopen it (required for conda init to take effect)
-run "conda env create -f conda_env.yaml"

2) Now we can run our code on the cluster
-Open the terminal
-run "sbatch example.job"
    -example.job is a so called job-file used in the Slurm Framework to schedule code  
    execution 
    -the job-file consists of two parts: hardware specification and the code that is to 
    be executed
    -#SBATCH lines are used to specify the Hardware used for the code execution.
    You do not have to change anything in the Hardware configuration but if you want to
    increase the number of parallel enviorments, you might want to increase the number of 
    processor cores (#SBATCH --cpus-per-task). The number of cores should be equal to
    the number of enviorments
    -Below that there is the code you want to execute
    -First you run "source /home/sc.uni-leipzig.de/[YOUR_USERNAME]/.bashrc" to run the 
    code with the configurations on your personal account
    -then you load all the different modules that are required for code execution
    in our case (Anaconda3 for package management)
    -Lastly, actiavte your conda enviorment & let the agent train

3) Changing the configurations
-you might want to change the configurations of the training. Following option are 
currently implemented:
    --save_path # Where the weights are safed/accessed (Path to file)
    --seed_nr #number from 0-19 determining the seed used (int)
    --enviroment #Which enviorment will be used (GraphEnv, SeqGraphEnv) (str)
    --model #Which model you will used (PPO, A2C, DQN, DDQN) (str)
    --n_env #How much envirments will be used in parallel (int)

4) Check your training status by...
    - squeue -u YOUR_USERNAME #Status of your job (R=RUNNING, PD=PENDING)
    - seff PROCESS_ID #How much ressources your code uses (should be >0%)
    - Look into train.err & train.out files

