wandb: Currently logged in as: coyfelix7 (coyfelix7-universit-t-leipzig) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /home/sc.uni-leipzig.de/ci72buri/projects/Math_RL/Leipzig_Math_ML_Internship_SS25_RL_Counterexamples/Slurm/wandb/run-20250517_180859-e0xitx7p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-mountain-13
wandb: ‚≠êÔ∏è View project at https://wandb.ai/coyfelix7-universit-t-leipzig/math_ml
wandb: üöÄ View run at https://wandb.ai/coyfelix7-universit-t-leipzig/math_ml/runs/e0xitx7p
/home/sc.uni-leipzig.de/ci72buri/.conda/envs/math_ml/lib/python3.11/site-packages/gymnasium/envs/registration.py:527: UserWarning: [33mWARN: Using the latest versioned environment `Conjuncture2-SeqGraphEnv-v0` instead of the unversioned environment `Conjuncture2-SeqGraphEnv`.[0m
  logger.warn(
/home/sc.uni-leipzig.de/ci72buri/.conda/envs/math_ml/lib/python3.11/site-packages/gymnasium/envs/registration.py:736: UserWarning: [33mWARN: The environment is being initialised with render_mode='rgb_array' that is not in the possible render_modes (['human']).[0m
  logger.warn(
/home/sc.uni-leipzig.de/ci72buri/.conda/envs/math_ml/lib/python3.11/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run Model_PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.
  warnings.warn(
Traceback (most recent call last):
  File "/home/sc.uni-leipzig.de/ci72buri/projects/Math_RL/Leipzig_Math_ML_Internship_SS25_RL_Counterexamples/combinatorics_25/train.py", line 79, in <module>
    main()
  File "/home/sc.uni-leipzig.de/ci72buri/projects/Math_RL/Leipzig_Math_ML_Internship_SS25_RL_Counterexamples/combinatorics_25/train.py", line 48, in main
    m.model_train(save_path=args.save_path)
  File "/home/sc.uni-leipzig.de/ci72buri/projects/Math_RL/Leipzig_Math_ML_Internship_SS25_RL_Counterexamples/combinatorics_25/model/model.py", line 21, in model_train
    self.learn(total_timesteps=timesteps, callback=callbacks)
  File "/home/sc.uni-leipzig.de/ci72buri/.conda/envs/math_ml/lib/python3.11/site-packages/stable_baselines3/ppo/ppo.py", line 311, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "/home/sc.uni-leipzig.de/ci72buri/.conda/envs/math_ml/lib/python3.11/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 337, in learn
    self.train()
  File "/home/sc.uni-leipzig.de/ci72buri/.conda/envs/math_ml/lib/python3.11/site-packages/stable_baselines3/ppo/ppo.py", line 213, in train
    values, log_prob, entropy = self.policy.evaluate_actions(rollout_data.observations, actions)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sc.uni-leipzig.de/ci72buri/.conda/envs/math_ml/lib/python3.11/site-packages/stable_baselines3/common/policies.py", line 737, in evaluate_actions
    distribution = self._get_action_dist_from_latent(latent_pi)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sc.uni-leipzig.de/ci72buri/.conda/envs/math_ml/lib/python3.11/site-packages/stable_baselines3/common/policies.py", line 697, in _get_action_dist_from_latent
    return self.action_dist.proba_distribution(action_logits=mean_actions)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sc.uni-leipzig.de/ci72buri/.conda/envs/math_ml/lib/python3.11/site-packages/stable_baselines3/common/distributions.py", line 288, in proba_distribution
    self.distribution = Categorical(logits=action_logits)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sc.uni-leipzig.de/ci72buri/.conda/envs/math_ml/lib/python3.11/site-packages/torch/distributions/categorical.py", line 69, in __init__
    self._num_events = self._param.size()[-1]
                       ^^^^^^^^^^^^^^^^^^
KeyboardInterrupt

ERROR conda.cli.main_run:execute(124): `conda run python /home/sc.uni-leipzig.de/ci72buri/projects/Math_RL/Leipzig_Math_ML_Internship_SS25_RL_Counterexamples/combinatorics_25/train.py --enviroment Conjuncture2-SeqGraphEnv` failed. (See above for error)
